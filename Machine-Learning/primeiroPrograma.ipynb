{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor() # definido a conversão de imagem para o tensor\n",
    "\n",
    "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) # Carrega a parte de treino do dataset\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) # Cria um buffer para pegar os dados por partes\n",
    "\n",
    "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform) # Carrega a parte de validação do dataset\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=False) # Cria um buffer para pegar os dados por partes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16bdb582900>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZr0lEQVR4nO3df0zU9x3H8df5g6u23DFEOJjo0La6VWWZU0Zs/TGJwhKj1T+07R/aGI0Omynr2rC0ItsSNpu4po3TfzZdk6qdSdXUP0wUAdMNXLQaY7YRIWxqBFxNvEOsaOSzP4i3nmL1zjve3Pl8JN9E7r7HvfvdN/fclzs+eJxzTgAADLAh1gMAAJ5MBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJgYZj3AvXp7e3X58mWlp6fL4/FYjwMAiJJzTl1dXcrLy9OQIQ++zhl0Abp8+bLy8/OtxwAAPKaLFy9qzJgxD7x/0AUoPT1dUt/gPp/PeBoAQLRCoZDy8/PDr+cPkrAAbdu2Te+99546OjpUWFioDz/8UDNmzHjo4+7+2M3n8xEgAEhiD3sbJSEfQvjkk09UUVGhqqoqffHFFyosLNSCBQt05cqVRDwdACAJJSRAW7du1erVq/X666/re9/7nnbs2KGRI0fqT3/6UyKeDgCQhOIeoFu3bunUqVMqKSn5/5MMGaKSkhI1Njbet39PT49CoVDEBgBIfXEP0Jdffqk7d+4oJycn4vacnBx1dHTct39NTY38fn944xNwAPBkMP9F1MrKSgWDwfB28eJF65EAAAMg7p+Cy8rK0tChQ9XZ2Rlxe2dnpwKBwH37e71eeb3eeI8BABjk4n4FlJaWpmnTpqm2tjZ8W29vr2pra1VcXBzvpwMAJKmE/B5QRUWFVqxYoR/+8IeaMWOG3n//fXV3d+v1119PxNMBAJJQQgK0bNky/fe//9WmTZvU0dGh73//+zp8+PB9H0wAADy5PM45Zz3E14VCIfn9fgWDQVZCAIAk9Kiv4+afggMAPJkIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJuAdo8+bN8ng8EdukSZPi/TQAgCQ3LBHf9IUXXtDRo0f//yTDEvI0AIAklpAyDBs2TIFAIBHfGgCQIhLyHtD58+eVl5en8ePH67XXXtOFCxceuG9PT49CoVDEBgBIfXEPUFFRkXbt2qXDhw9r+/btamtr00svvaSurq5+96+pqZHf7w9v+fn58R4JADAIeZxzLpFPcO3aNY0bN05bt27VqlWr7ru/p6dHPT094a9DoZDy8/MVDAbl8/kSORoAIAFCoZD8fv9DX8cT/umAjIwMPf/882ppaen3fq/XK6/Xm+gxAACDTMJ/D+j69etqbW1Vbm5uop8KAJBE4h6gN998Uw0NDfr3v/+tv/3tb3r55Zc1dOhQvfLKK/F+KgBAEov7j+AuXbqkV155RVevXtXo0aP14osvqqmpSaNHj473UwEAkljcA7R37954f0sAQApiLTgAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwMcx6ADzY3Llzo35MfX191I+ZM2dO1I+RpNmzZw/Ic8U6H4DBjSsgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMCExznnrIf4ulAoJL/fr2AwKJ/PZz1O3AzUwqJIXbEsyhrLgrEDafPmzdYjIAEe9XWcKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwASLkQ6QWBZdrK6ujv8gAB5ZXV1d1I+JZdHYVMNipACAQY0AAQBMRB2g48ePa+HChcrLy5PH49GBAwci7nfOadOmTcrNzdWIESNUUlKi8+fPx2teAECKiDpA3d3dKiws1LZt2/q9f8uWLfrggw+0Y8cOnThxQk8//bQWLFigmzdvPvawAIDUMSzaB5SVlamsrKzf+5xzev/99/XOO+9o0aJFkqSPPvpIOTk5OnDggJYvX/540wIAUkZc3wNqa2tTR0eHSkpKwrf5/X4VFRWpsbGx38f09PQoFApFbACA1BfXAHV0dEiScnJyIm7PyckJ33evmpoa+f3+8Jafnx/PkQAAg5T5p+AqKysVDAbD28WLF61HAgAMgLgGKBAISJI6Ozsjbu/s7Azfdy+v1yufzxexAQBSX1wDVFBQoEAgoNra2vBtoVBIJ06cUHFxcTyfCgCQ5KL+FNz169fV0tIS/rqtrU1nzpxRZmamxo4dqw0bNug3v/mNnnvuORUUFOjdd99VXl6eFi9eHM+5AQBJLuoAnTx5UnPnzg1/XVFRIUlasWKFdu3apbfeekvd3d1as2aNrl27phdffFGHDx/WU089Fb+pAQBJj8VIB0h9fX3Uj4llMdJYngdA/LCAKYuRAgAGOQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJiI+s8xIDYDtdrt7NmzB+R5BrtYVhJPRVVVVTE9rqGhIerHsBJ7n1iOQ6qthv2ouAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEx4nHPOeoivC4VC8vv9CgaD8vl81uMASCCPx2M9QtzFsrBoXV1d/Acx9Kiv41wBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmhlkPACA11NfXW48wKFRVVVmPkDS4AgIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATLAYKYD7bN68OerHVFdXx38QY3V1dVE/Zs6cOfEfJEVxBQQAMEGAAAAmog7Q8ePHtXDhQuXl5cnj8ejAgQMR969cuVIejydiKy0tjde8AIAUEXWAuru7VVhYqG3btj1wn9LSUrW3t4e3PXv2PNaQAIDUE/WHEMrKylRWVvaN+3i9XgUCgZiHAgCkvoS8B1RfX6/s7GxNnDhR69at09WrVx+4b09Pj0KhUMQGAEh9cQ9QaWmpPvroI9XW1up3v/udGhoaVFZWpjt37vS7f01Njfx+f3jLz8+P90gAgEEo7r8HtHz58vC/p0yZoqlTp2rChAmqr6/XvHnz7tu/srJSFRUV4a9DoRARAoAnQMI/hj1+/HhlZWWppaWl3/u9Xq98Pl/EBgBIfQkP0KVLl3T16lXl5uYm+qkAAEkk6h/BXb9+PeJqpq2tTWfOnFFmZqYyMzNVXV2tpUuXKhAIqLW1VW+99ZaeffZZLViwIK6DAwCSW9QBOnnypObOnRv++u77NytWrND27dt19uxZ/fnPf9a1a9eUl5en+fPn69e//rW8Xm/8pgYAJD2Pc85ZD/F1oVBIfr9fwWCQ94OAxxTLoqJS6i0sGusCobEsRopHfx1nLTgAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYiPuf5AaQGF//MyiPqr6+Pv6DGKuqqor6MbGuCo7E4goIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBYqSAgVgWCWVh0T4sLJo6uAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEx4nHPOeoivC4VC8vv9CgaD8vl81uMADxXLIqFz586N/yBJaJC9/CBOHvV1nCsgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMDEMOsBgMGEhUX71NXVRf2YOXPmxH8QpDSugAAAJggQAMBEVAGqqanR9OnTlZ6eruzsbC1evFjNzc0R+9y8eVPl5eUaNWqUnnnmGS1dulSdnZ1xHRoAkPyiClBDQ4PKy8vV1NSkI0eO6Pbt25o/f766u7vD+2zcuFGfffaZ9u3bp4aGBl2+fFlLliyJ++AAgOQW1YcQDh8+HPH1rl27lJ2drVOnTmnWrFkKBoP64x//qN27d+vHP/6xJGnnzp367ne/q6amJv3oRz+K3+QAgKT2WO8BBYNBSVJmZqYk6dSpU7p9+7ZKSkrC+0yaNEljx45VY2Njv9+jp6dHoVAoYgMApL6YA9Tb26sNGzZo5syZmjx5siSpo6NDaWlpysjIiNg3JydHHR0d/X6fmpoa+f3+8Jafnx/rSACAJBJzgMrLy3Xu3Dnt3bv3sQaorKxUMBgMbxcvXnys7wcASA4x/SLq+vXrdejQIR0/flxjxowJ3x4IBHTr1i1du3Yt4iqos7NTgUCg3+/l9Xrl9XpjGQMAkMSiugJyzmn9+vXav3+/jh07poKCgoj7p02bpuHDh6u2tjZ8W3Nzsy5cuKDi4uL4TAwASAlRXQGVl5dr9+7dOnjwoNLT08Pv6/j9fo0YMUJ+v1+rVq1SRUWFMjMz5fP59MYbb6i4uJhPwAEAIkQVoO3bt0u6f82nnTt3auXKlZKk3//+9xoyZIiWLl2qnp4eLViwQH/4wx/iMiwAIHV4nHPOeoivC4VC8vv9CgaD8vl81uMgScWyqKgkVVdXD9hzDYRYFhWVWFgUj+dRX8dZCw4AYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmYvqLqMBAmjt3btSPGcwrVEuxrTZdVVU1IM8DDBSugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEyxGigGViguLxoKFRQGugAAARggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEyxGipixsGifurq6qB/DwqIAV0AAACMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkWI0XMC4TOnj17QB4z2LGwKBAbroAAACYIEADARFQBqqmp0fTp05Wenq7s7GwtXrxYzc3NEfvMmTNHHo8nYlu7dm1chwYAJL+oAtTQ0KDy8nI1NTXpyJEjun37tubPn6/u7u6I/VavXq329vbwtmXLlrgODQBIflF9COHw4cMRX+/atUvZ2dk6deqUZs2aFb595MiRCgQC8ZkQAJCSHus9oGAwKEnKzMyMuP3jjz9WVlaWJk+erMrKSt24ceOB36Onp0ehUChiAwCkvpg/ht3b26sNGzZo5syZmjx5cvj2V199VePGjVNeXp7Onj2rt99+W83Nzfr000/7/T41NTWqrq6OdQwAQJKKOUDl5eU6d+6cPv/884jb16xZE/73lClTlJubq3nz5qm1tVUTJky47/tUVlaqoqIi/HUoFFJ+fn6sYwEAkkRMAVq/fr0OHTqk48ePa8yYMd+4b1FRkSSppaWl3wB5vV55vd5YxgAAJLGoAuSc0xtvvKH9+/ervr5eBQUFD33MmTNnJEm5ubkxDQgASE1RBai8vFy7d+/WwYMHlZ6ero6ODkmS3+/XiBEj1Nraqt27d+snP/mJRo0apbNnz2rjxo2aNWuWpk6dmpD/AABAcooqQNu3b5d0/9pXO3fu1MqVK5WWlqajR4/q/fffV3d3t/Lz87V06VK98847cRsYAJAaov4R3DfJz89XQ0PDYw0EAHgyeNzDqjLAQqGQ/H6/gsGgfD6f9TgAgCg96us4i5ECAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgYpj1APdyzkmSQqGQ8SQAgFjcff2++3r+IIMuQF1dXZKk/Px840kAAI+jq6tLfr//gfd73MMSNcB6e3t1+fJlpaeny+PxRNwXCoWUn5+vixcvyufzGU1oj+PQh+PQh+PQh+PQZzAcB+ecurq6lJeXpyFDHvxOz6C7AhoyZIjGjBnzjfv4fL4n+gS7i+PQh+PQh+PQh+PQx/o4fNOVz118CAEAYIIAAQBMJFWAvF6vqqqq5PV6rUcxxXHow3How3How3Hok0zHYdB9CAEA8GRIqisgAEDqIEAAABMECABgggABAEwkTYC2bdum73znO3rqqadUVFSkv//979YjDbjNmzfL4/FEbJMmTbIeK+GOHz+uhQsXKi8vTx6PRwcOHIi43zmnTZs2KTc3VyNGjFBJSYnOnz9vM2wCPew4rFy58r7zo7S01GbYBKmpqdH06dOVnp6u7OxsLV68WM3NzRH73Lx5U+Xl5Ro1apSeeeYZLV26VJ2dnUYTJ8ajHIc5c+bcdz6sXbvWaOL+JUWAPvnkE1VUVKiqqkpffPGFCgsLtWDBAl25csV6tAH3wgsvqL29Pbx9/vnn1iMlXHd3twoLC7Vt27Z+79+yZYs++OAD7dixQydOnNDTTz+tBQsW6ObNmwM8aWI97DhIUmlpacT5sWfPngGcMPEaGhpUXl6upqYmHTlyRLdv39b8+fPV3d0d3mfjxo367LPPtG/fPjU0NOjy5ctasmSJ4dTx9yjHQZJWr14dcT5s2bLFaOIHcElgxowZrry8PPz1nTt3XF5enqupqTGcauBVVVW5wsJC6zFMSXL79+8Pf93b2+sCgYB77733wrddu3bNeb1et2fPHoMJB8a9x8E551asWOEWLVpkMo+VK1euOEmuoaHBOdf3v/3w4cPdvn37wvv885//dJJcY2Oj1ZgJd+9xcM652bNnu5/97Gd2Qz2CQX8FdOvWLZ06dUolJSXh24YMGaKSkhI1NjYaTmbj/PnzysvL0/jx4/Xaa6/pwoUL1iOZamtrU0dHR8T54ff7VVRU9ESeH/X19crOztbEiRO1bt06Xb161XqkhAoGg5KkzMxMSdKpU6d0+/btiPNh0qRJGjt2bEqfD/ceh7s+/vhjZWVlafLkyaqsrNSNGzcsxnugQbcY6b2+/PJL3blzRzk5ORG35+Tk6F//+pfRVDaKioq0a9cuTZw4Ue3t7aqurtZLL72kc+fOKT093Xo8Ex0dHZLU7/lx974nRWlpqZYsWaKCggK1trbql7/8pcrKytTY2KihQ4dajxd3vb292rBhg2bOnKnJkydL6jsf0tLSlJGREbFvKp8P/R0HSXr11Vc1btw45eXl6ezZs3r77bfV3NysTz/91HDaSIM+QPi/srKy8L+nTp2qoqIijRs3Tn/5y1+0atUqw8kwGCxfvjz87ylTpmjq1KmaMGGC6uvrNW/ePMPJEqO8vFznzp17It4H/SYPOg5r1qwJ/3vKlCnKzc3VvHnz1NraqgkTJgz0mP0a9D+Cy8rK0tChQ+/7FEtnZ6cCgYDRVINDRkaGnn/+ebW0tFiPYubuOcD5cb/x48crKysrJc+P9evX69ChQ6qrq4v48y2BQEC3bt3StWvXIvZP1fPhQcehP0VFRZI0qM6HQR+gtLQ0TZs2TbW1teHbent7VVtbq+LiYsPJ7F2/fl2tra3Kzc21HsVMQUGBAoFAxPkRCoV04sSJJ/78uHTpkq5evZpS54dzTuvXr9f+/ft17NgxFRQURNw/bdo0DR8+POJ8aG5u1oULF1LqfHjYcejPmTNnJGlwnQ/Wn4J4FHv37nVer9ft2rXL/eMf/3Br1qxxGRkZrqOjw3q0AfXzn//c1dfXu7a2NvfXv/7VlZSUuKysLHflyhXr0RKqq6vLnT592p0+fdpJclu3bnWnT592//nPf5xzzv32t791GRkZ7uDBg+7s2bNu0aJFrqCgwH311VfGk8fXNx2Hrq4u9+abb7rGxkbX1tbmjh496n7wgx+45557zt28edN69LhZt26d8/v9rr6+3rW3t4e3GzduhPdZu3atGzt2rDt27Jg7efKkKy4udsXFxYZTx9/DjkNLS4v71a9+5U6ePOna2trcwYMH3fjx492sWbOMJ4+UFAFyzrkPP/zQjR071qWlpbkZM2a4pqYm65EG3LJly1xubq5LS0tz3/72t92yZctcS0uL9VgJV1dX5yTdt61YscI51/dR7Hfffdfl5OQ4r9fr5s2b55qbm22HToBvOg43btxw8+fPd6NHj3bDhw9348aNc6tXr065/5PW33+/JLdz587wPl999ZX76U9/6r71rW+5kSNHupdfftm1t7fbDZ0ADzsOFy5ccLNmzXKZmZnO6/W6Z5991v3iF79wwWDQdvB78OcYAAAmBv17QACA1ESAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmPgfUMOa0t2DOScAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "imagens, etiquetas = dataiter.__next__()\n",
    "plt.imshow(imagens[1].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(imagens[0].shape) # para verificar as dimensões do tensor de cada imagem\n",
    "print(etiquetas[0].shape) # para  verificar as dimensões do tensor de cada etiqueta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelo(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super(Modelo, self).__init__()\n",
    "        self.linear1=nn.Linear(28*28, 128) # camada de entrada, 784 neurônios que se ligam a 128\n",
    "        self.linear2=nn.Linear(128, 64) # camada interna 1, 128 neurônios que se ligam a 64\n",
    "        self.linear3=nn.Linear(64, 10) # camada interna 2, 64 neurônios que se ligam a 10\n",
    "        # Para a camada de saida não e necessario definir nada pois só precisamos pegar o output da camada interna 2\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.linear1(X)) # função de ativação da camada de entrada para a camada interna 1\n",
    "        X = F.relu(self.linear1(X)) # função de ativação da camada interna 1 para a camada interna 2\n",
    "        X = self.linear3(X) # função de ativação da camada interna 1 para a camada de saída, nesse caso f(x) = x\n",
    "        return F.log_softmax(X, dim=1) # dados utilizados para calcular a perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino(modelo, trainloader, device):\n",
    "\n",
    "    otimizador = optim.SGD(modelo.parameters(),  lr=0.01, momentum=0.5) # define a politica de atualização dos pesos e da bias\n",
    "    inicio = time() # timer para sabermos quanto tempo levou o treino\n",
    "\n",
    "    criterio = nn.NLLLoss() # definido o criterio para calcular a perda\n",
    "    EPOCHS = 10 # numero de epochs que o algoritmo rodará\n",
    "    modelo.train() # ativando o modo de treinamento do modelo\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        perda_acumulada = 0 # inicialização da perda acumulada da epoch em questão\n",
    "\n",
    "        for images, etiquetas in trainloader:\n",
    "            \n",
    "            images = images.view(images.shape[0], -1) # convertendo as imagens para \"vetores\" de 28*28 casas para ficarem compativeis com a rede neural\n",
    "            otimizador.zero_grad() # zerando os  gradientes por conta do ciclo anterior\n",
    "\n",
    "            output = modelo(imagens.to(device)) # colocando os dados no modelo\n",
    "            perda_instantanea = criterio(output, etiquetas.to(device)) # calculando a perda da epoch em questão\n",
    "\n",
    "            perda_instantanea.backward() # back propagation a partir da perda\n",
    "\n",
    "            otimizador.step() # atualizando os pesos e bias\n",
    "\n",
    "            perda_acumulada += perda_instantanea.item() # atualização da perda acumulada\n",
    "\n",
    "        else:\n",
    "            print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
    "    print(\"\\nTempo de treino (em minutos) =\",(time()-inicio)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacao(modelo, valloader, device):\n",
    "    conta_corretas, conta_todas = 0, 0\n",
    "    for imagens,etiquetas in valloader:\n",
    "        for i in range(len(etiquetas)):\n",
    "            img = imagens[i].view(1,784)\n",
    "            # desativar o autograd para acelerar a validação. Grafos computacionais dinâmicos tem um custo alto de processamento\n",
    "            with torch.no_grad():\n",
    "                logps = modelo(img.to(device)) # output do modelo em escala logaritmica\n",
    "            \n",
    "            ps = torch.exp(logps) # converte output para escala normal(lembrando que é um tensor)\n",
    "            probab = list(ps.cpu().numpy()[0])\n",
    "            etiqueta_pred = probab.index(max(probab)) # converte o tensor em número, no caso, o número que o modelo previu como correto\n",
    "            etiqueta_certa = etiquetas.numpy()[i]\n",
    "            if(etiqueta_certa == etiqueta_pred): # compara a previsão com o valor correto\n",
    "                conta_corretas += 1\n",
    "            conta_todas += 1\n",
    "\n",
    "    print(\"Total de imagens testadas =\", conta_todas)\n",
    "    print(\"\\nPrecisão do modelo = {}%\".format(conta_corretas*100/conta_todas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Modelo(\n",
       "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = Modelo()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\" ) \n",
    "modelo.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
